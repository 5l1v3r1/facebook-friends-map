{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving latest notebooks to Python...\n",
      "[NbConvertApp] Converting notebook extract.ipynb to script\n",
      "[NbConvertApp] Writing 13867 bytes to extract.py\n"
     ]
    }
   ],
   "source": [
    "import argparse, json, os, glob, time, sys, requests, pandas as pd\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common import exceptions\n",
    "from datetime import datetime\n",
    "\n",
    "ts = datetime.now().strftime('%Y-%m-%d_%H%M')\n",
    "friends_html = 'db/index.html'\n",
    "profiles_dir = 'db/profiles/'\n",
    "db_index = 'db/index.json'\n",
    "db_profiles = 'db/profiles.json'\n",
    "db_loc = 'db/locations.json'\n",
    "db_geo = 'db/geo.json'\n",
    "\n",
    "#Set up & check environment\n",
    "if not os.path.exists(profiles_dir):\n",
    "    os.makedirs(profiles_dir)\n",
    "if not os.path.exists(db_profiles):\n",
    "    with open(db_profiles,'w') as f:\n",
    "        f.write(\"{}\")\n",
    "\n",
    "#Determine execution context\n",
    "try:\n",
    "    get_ipython()\n",
    "    is_nb = 1\n",
    "    print('Saving latest notebooks to Python...')\n",
    "    !jupyter nbconvert --to script *.ipynb\n",
    "except:\n",
    "    is_nb = 0\n",
    "    print('Script is running from shell')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data from Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_browser():\n",
    "    #Setup browser\n",
    "    print(\"Opening Browser...\")\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--disable-infobars\")\n",
    "    options.add_argument(\"--mute-audio\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    #options.add_argument(\"headless\")\n",
    "    options.add_experimental_option(\"prefs\",{\"profile.managed_default_content_settings.images\":2})\n",
    "    browser = Chrome(options=options)\n",
    "\n",
    "    return browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_in():\n",
    "    #Sign in\n",
    "    fb_start_page = 'https://m.facebook.com/'\n",
    "    if os.getenv('fb_pass', None):\n",
    "        fb_user = os.getenv('fb_user')\n",
    "        fb_pass = os.getenv('fb_pass')\n",
    "        print(\"Logging in %s automatically...\" % fb_user)\n",
    "        browser.get(fb_start_page)\n",
    "        email_id = browser.find_element_by_id(\"m_login_email\")\n",
    "        pass_id = browser.find_element_by_id(\"m_login_password\")\n",
    "        email_id.send_keys(fb_user)\n",
    "        pass_id.send_keys(fb_pass)\n",
    "        pass_id.send_keys(u'\\ue007')\n",
    "    else:\n",
    "        browser.get(fb_start_page)\n",
    "        input(\"Please log into facebook and press enter after the page loads...\")\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_friends():\n",
    "    browser.get(\"https://m.facebook.com/me/friends\")\n",
    "    time.sleep(3)\n",
    "    print('Scrolling to bottom...')\n",
    "    #Scroll to bottom\n",
    "    while browser.find_elements_by_css_selector('#m_more_friends'):\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    #Save friend list\n",
    "    with open (friends_html, 'w') as f:\n",
    "        f.write(browser.page_source)\n",
    "        print('%s) Downloaded' % friends_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_friends():\n",
    "    print('Indexing friends list...')    \n",
    "    data = []\n",
    "    browser.get('file:///' + os.getcwd() + '/' + friends_html)\n",
    "    base = '(//*[@class=\"_55wp _7om2 _5pxa\"])'\n",
    "    num_items = len(browser.find_elements_by_xpath(base))\n",
    "    print('Scanning %s friends...' % (num_items))\n",
    "    for i in range(1,num_items+1):\n",
    "        b = base + '['+str(i)+']/'\n",
    "        info = json.loads(browser.find_element_by_xpath(b+'div[2]/div[1]/div[2]/div[3]').get_attribute('data-store'))\n",
    "        alias = '' if info['is_deactivated'] else browser.find_element_by_xpath(b+'div[2]/div[1]/*[1]/a').get_attribute('href')[8:]\n",
    "        d = {\n",
    "            'id': info['id'],\n",
    "            'name': browser.find_element_by_xpath(b+'div[2]/div[1]/*[1]/a').text,\n",
    "            'is_deactivated': info['is_deactivated'],\n",
    "            'alias': alias,\n",
    "            'photo_url': browser.find_element_by_xpath(b+'div[1]/a/i').get_attribute('style').split('(\"')[1].split('\")')[0],\n",
    "            'mutual_friends': browser.find_element_by_xpath(b+'div[2]/div[1]/div[1]/div[1]/div[@data-sigil=\"m-add-friend-source-replaceable\"]').text\n",
    "            }\n",
    "        print('%s) %s' % (i,d['name']))\n",
    "        data.append(d)\n",
    "\n",
    "    with open(db_index, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print('Indexed %s friends to %s' % (i,db_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_profiles():\n",
    "    print('Downloading profiles from index...')\n",
    "    with open(db_index, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for i,d in enumerate(data):\n",
    "        print('%s) %s' % (i+1,d['name']),end=\"\",flush=True)\n",
    "        if d['is_deactivated']:\n",
    "            print(' // Skipped (Profile deactivated)')\n",
    "        else:\n",
    "            fname = profiles_dir + str(d['id']) + '.html'\n",
    "            if os.path.exists(fname):\n",
    "                print(\" // Skipped (Already Exists): %s\" % (fname))\n",
    "            else:\n",
    "                browser.get('https://mbasic.facebook.com/profile.php?v=info&id='+str(d['id']))\n",
    "                time.sleep(1)\n",
    "                if browser.find_elements_by_css_selector('#login_form') or browser.find_elements_by_css_selector('#mobile_login_bar'):\n",
    "                    print('\\nBrowser is not logged into facebook! Please run again to login & resume.')\n",
    "                    sys.exit(1)\n",
    "                else:\n",
    "                    with open (fname, 'w') as f:\n",
    "                        f.write(browser.page_source)\n",
    "                        print(' // Downloaded to %s' % fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_profiles():\n",
    "    sections = {\n",
    "        'photo_url': {'src':'//div[@id=\"objects_container\"]//a/img[@alt][1]'},\n",
    "        'tagline': {'txt':'//*[@id=\"root\"]/div[1]/div[1]/div[2]/div[2]'},\n",
    "        'about': {'txt':'//div[@id=\"bio\"]/div/div[2]/div'},\n",
    "        'quotes': {'txt':'//*[@id=\"quote\"]/div/div[2]/div'},\n",
    "        'rel': {'txt':'//div[@id=\"relationship\"]/div/div[2]'},\n",
    "        'rel_partner': {'href':'//div[@id=\"relationship\"]/div/div[2]//a'},\n",
    "        'details': {'table':'(//div[2]/div//div[@title]//'},\n",
    "        'work': {'workedu':'//*[@id=\"work\"]/div[1]/div[2]/div'},\n",
    "        'education': {'workedu':'//*[@id=\"education\"]/div[1]/div[2]/div'},\n",
    "        'family': {'fam':'//*[@id=\"family\"]/div/div[2]/div'},\n",
    "        'life_events': {'years':'(//div[@id=\"year-overviews\"]/div[1]/div[2]/div[1]/div/div[1])'}\n",
    "    }\n",
    "    \n",
    "    with open(db_index) as f:\n",
    "        friends_list = json.load(f)\n",
    "    with open(db_profiles) as f:\n",
    "        profiles = json.load(f)\n",
    "    already_parsed = []\n",
    "    for i,profile in enumerate(profiles):\n",
    "        already_parsed.append(profile['id'])\n",
    "        \n",
    "    for i,r in enumerate(friends_list):\n",
    "        print('%s) %s' % (i+1,r['name']),end=\"\",flush=True)\n",
    "        if r['is_deactivated']:\n",
    "            print(' // Profile deactivated, skipping...')\n",
    "        elif r['id'] in already_parsed:\n",
    "            print(' // Already in profile database, skipping...')\n",
    "        else:\n",
    "            d = {'id': r['id'],'name': r['name'],'alias': r['alias']}\n",
    "            profile = 'file://'+os.getcwd()+'/'+profiles_dir+str(d['id'])+'.html'\n",
    "            print(' // '+profile)\n",
    "            browser.get(profile)\n",
    "            x = browser.find_element_by_xpath\n",
    "            xs = browser.find_elements_by_xpath\n",
    "            for k,v in sections.items():\n",
    "                try:\n",
    "                    if 'src' in v:\n",
    "                        d[str(k)] = x(v['src']).get_attribute('src')\n",
    "                    elif 'txt' in v:\n",
    "                        d[str(k)] = x(v['txt']).text\n",
    "                    elif 'href' in v:\n",
    "                        d[str(k)] = x(v['href']).get_attribute('href')[8:].split('?')[0]\n",
    "                    elif 'table' in v:\n",
    "                        d['details'] = []\n",
    "                        rows = xs(v['table']+'td[1])')\n",
    "                        for i in range (1, len(rows)+1):\n",
    "                            deets_key = x(v['table']+'td[1])'+'['+str(i)+']').text\n",
    "                            deets_val = x(v['table']+'td[2])'+'['+str(i)+']').text\n",
    "                            d['details'].append({deets_key:deets_val})\n",
    "                    elif 'workedu' in v:\n",
    "                        d[str(k)] = []\n",
    "                        base = v['workedu']\n",
    "                        rows = xs(base)\n",
    "                        for i in range (1, len(rows)+1):\n",
    "                            dd = {}\n",
    "                            dd['link'] = x(base+'['+str(i)+']'+'/div/div[1]//a').get_attribute('href')[8:].split('&')[0].split('/')[0]\n",
    "                            dd['org'] = x(base+'['+str(i)+']'+'/div/div[1]//a').text\n",
    "                            dd['lines'] = []\n",
    "                            lines = xs(base+'['+str(i)+']'+'/div/div[1]/div')\n",
    "                            for l in range (2, len(lines)+1):\n",
    "                                line = x(base+'['+str(i)+']'+'/div/div[1]/div'+'['+str(l)+']').text\n",
    "                                dd['lines'].append(line)\n",
    "                            d[str(k)].append(dd)\n",
    "                    elif 'fam' in v:\n",
    "                        d[str(k)] = []\n",
    "                        base = v['fam']\n",
    "                        rows = xs(base)\n",
    "                        for i in range (1, len(rows)+1):\n",
    "                            d[str(k)].append({\n",
    "                                'name': x(base+'['+str(i)+']'+'//h3[1]').text,\n",
    "                                'rel': x(base+'['+str(i)+']'+'//h3[2]').text,\n",
    "                                'alias': x(base+'['+str(i)+']'+'//h3[1]/a').get_attribute('href')[8:].split('?')[0]\n",
    "                            })\n",
    "                    elif 'life_events' in k:\n",
    "                        d[str(k)] = []\n",
    "                        base = v['years']\n",
    "                        years = xs(base)\n",
    "                        for i in range (1,len(years)+1):\n",
    "                            year = x(base+'['+str(i)+']'+'/div[1]').text\n",
    "                            events = xs(base+'['+str(i)+']'+'/div/div/a')\n",
    "                            for e in range(1,len(events)+1):\n",
    "                                event = x('('+base+'['+str(i)+']'+'/div/div/a)'+'['+str(e)+']')\n",
    "                                d[str(k)].append({\n",
    "                                    'year': year,\n",
    "                                    'title': event.text,\n",
    "                                    'link': event.get_attribute('href')[8:].split('refid')[0]\n",
    "                                })\n",
    "                    \n",
    "                except exceptions.NoSuchElementException:\n",
    "                    pass\n",
    "            \n",
    "            profiles.append(d)\n",
    "\n",
    "            with open(db_profiles, 'w') as f:\n",
    "                json.dump(profiles, f, indent=2)\n",
    "            \n",
    "    print('Indexed %s friends to %s' % (i,db_profiles)) #update how it counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_locations():\n",
    "    with open(db_profiles) as f:\n",
    "        profiles = json.load(f)\n",
    "    locations = []\n",
    "    for idx,r in enumerate(profiles):\n",
    "        print('%s) %s (%s): ' % (idx+1,r['name'],r['id']),end=\"\",flush=True)\n",
    "        loc = ''\n",
    "        for i,d in enumerate(r['details']):\n",
    "            if d.get('Address'):\n",
    "                loc = d.get('Address')\n",
    "        for i,d in enumerate(r['details']):\n",
    "            if d.get('Current City'):\n",
    "                loc = d.get('Current City')  \n",
    "        if loc:\n",
    "            d = {\n",
    "                'id': r['id'],\n",
    "                'name': r['name'],\n",
    "                'location': loc\n",
    "            }\n",
    "            print(d['location'])\n",
    "            locations.append(d)\n",
    "        else:\n",
    "            print('(no location)')\n",
    "    \n",
    "    with open(db_loc,'w') as f:\n",
    "        json.dump(locations, f, indent=4)\n",
    "    print('Indexed %s friends locations to %s' % (len(locations),db_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode_locations():\n",
    "    with open(db_loc) as f:\n",
    "        data = json.load(f)\n",
    "    locations = []\n",
    "    for i,r in enumerate(data):\n",
    "        locations.append(r['location'])\n",
    "    unique_locs = list(set(locations))\n",
    "    url_base = 'https://api.mapbox.com/geocoding/v5/mapbox.places/'\n",
    "    api_token = os.getenv('mapbox_token')\n",
    "    print('Geocoding locations from profiles...')\n",
    "    geos = []\n",
    "    for location in unique_locs:\n",
    "        r = requests.get(url_base + location + '.json',\n",
    "         params={\n",
    "             'access_token': api_token,\n",
    "             'limit': 1\n",
    "         })\n",
    "        coordinates = r.json()['features'][0]['geometry']['coordinates']\n",
    "        print('%s : %s' % (location ,coordinates))\n",
    "        geos.append({location:coordinates})\n",
    "        print('-'*20)\n",
    "    \n",
    "    with open(db_geo,'w') as f:\n",
    "        json.dump(geos, f, indent=4)\n",
    "    print('Indexed %s coordinates to %s' % (len(geos),db_geo))\n",
    "    \n",
    "#geocode_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running notebook stuff\n"
     ]
    }
   ],
   "source": [
    "if is_nb:\n",
    "    print('Running notebook stuff')\n",
    "    #browser = start_browser()\n",
    "    #parse_profiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json2csv():\n",
    "    #Convert index JSON to CSV\n",
    "    df = pd.read_json(db_index)\n",
    "    df.to_csv('db/index'+ts+'.csv')\n",
    "    print('Saved to db/index'+ts+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytics():\n",
    "    with open(db_index) as f:\n",
    "        friends_list = json.load(f)\n",
    "    detail_files = sorted(glob.glob(profiles_dir + '*.html'), key=os.path.getmtime)\n",
    "    \n",
    "    print('-- Startup check --')\n",
    "    print('# Friends: %s' % len(friends_list))\n",
    "    print('# Profile Files: %s' % len(detail_files))\n",
    "    print('# Profiles parsed: %s' % len(db_profiles))\n",
    "    print('# Remaining files: %s' % (len(friends_list)-len(detail_files)))\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shell application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__' and is_nb == 0:\n",
    "    parser = argparse.ArgumentParser(description='Facebook friends profile exporter')\n",
    "    parser.add_argument('--index', action='store_true', help='Index friends list')\n",
    "    parser.add_argument('--download', action='store_true', help='Download friends profiles')\n",
    "    parser.add_argument('--parse', action='store_true', help='Parse profiles to JSON')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    browser = start_browser()\n",
    "    try:\n",
    "        if args.index:\n",
    "            sign_in()\n",
    "            download_friends()\n",
    "            index_friends()\n",
    "        elif args.download:\n",
    "            sign_in()\n",
    "            download_profiles()\n",
    "        elif args.parse:\n",
    "            parse_profiles()\n",
    "        else:\n",
    "            sign_in(browser)\n",
    "            download_friends()\n",
    "            index_friends()\n",
    "            download_profiles()\n",
    "            parse_profiles()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('\\nThanks for using the script! Please raise any issues at https://github.com/jcontini/facebook-scraper/issues.')\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
